{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this project, we will be creating a predictive model for customer churn prediction of a fictional music streaming service: Sparkify (similar to Spotify and Pandora). Churn prediction is about making use of customer data to predict the likelihood of customers discontinuing their subscription in the future. Predicting churn rate is important because it can help Sparkify to identify and improve areas where customer services is lacking. So churn prediction helps to prevent individuals from discontinuing their subscription. According to [ClickZ](https://www.clickz.com/are-ecommerce-customer-retention-strategies-improving/105454/), the probability of selling to an existing customer is 60 - 70%. However, the probability of selling to a new prospect is just 5-20%.\n",
    "So it is very important to keep the existing customer around.\n",
    "\n",
    "## Data\n",
    "There are two dataset made avaliable, a full dataset (12GB) and a tiny subset (240Mb) sample from the full dataset. We will use the subset for data exploration, feature engineering and model selection on local machine. Its more time and computationally efficient to do all the modelling work in a small dataset than working on full dataset. If the subset of data is indeed representative of the full dataset, feature engineering and hyperparameters tuned in the sample dataset should applicable to the full dataset. Once the feature enginnering and the best model are identified, we will use the model for modelling the full dataset on Amazon AWS EMR cluster. \n",
    "\n",
    "\n",
    "## Project aim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:41:02.685017Z",
     "start_time": "2019-09-02T17:41:02.382346Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import udf, col, count, avg, stddev, isnull, when, isnan \n",
    "from pyspark.sql.functions import desc, countDistinct, min, max\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.types import IntegerType, DateType, StringType\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:24.937342Z",
     "start_time": "2019-09-02T15:28:19.830377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, we use the `medium-sparkify-event-data.json` data for the rest of the notebook. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:34.716998Z",
     "start_time": "2019-09-02T15:28:25.798757Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df = spark.read.json(\"../data/medium-sparkify-event-data.json\")\n",
    "customer_event_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:35.900782Z",
     "start_time": "2019-09-02T15:28:35.892876Z"
    }
   },
   "outputs": [],
   "source": [
    "type(customer_event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:36.996810Z",
     "start_time": "2019-09-02T15:28:36.987045Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:40.610285Z",
     "start_time": "2019-09-02T15:28:38.143434Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The shape of the customer event susbset {(customer_event_df.count(), len(customer_event_df.columns))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:47.420686Z",
     "start_time": "2019-09-02T15:28:47.414728Z"
    }
   },
   "outputs": [],
   "source": [
    "def counting_null(df):\n",
    "    \"\"\"\n",
    "    Return a dictionary contain the key value pairs of columns and their missing values.\n",
    "    :param df: pyspark dataframe\n",
    "    :return null_count: dict. the number of null values in each column\n",
    "    \"\"\"\n",
    "    \n",
    "    null_count = list()\n",
    "    for col in df.columns:\n",
    "        missing_values = df.filter((df[col] == \"\") \\\n",
    "                                   | df[col].isNull()\n",
    "                                   | isnan(df[col])).count()\n",
    "        null_count.append(missing_values)\n",
    "    return null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:48.678122Z",
     "start_time": "2019-09-02T15:28:48.671673Z"
    }
   },
   "outputs": [],
   "source": [
    "# equivalent to pandas describe\n",
    "def sumtable(df):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    summary = df.describe().toPandas().transpose()\n",
    "    summary = summary.rename(columns=summary.iloc[0]).drop(summary.index[0])\n",
    "    summary['null_count'] = counting_null(df)\n",
    "    del df\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "* Column `firstName`, `gender`, `lastNam`, `registration`, `location`, `userAgent` and `userId` have the same amount of missing values. All of the missing values are occurred in the same places. So we can removed all these 15700 missing values.\n",
    "* We will not remove the null values in `artist`, `length`, `song` column as some people may just login the app and not listen to any song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:51.269144Z",
     "start_time": "2019-09-02T15:28:51.085144Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df = customer_event_df.filter(customer_event_df.userId != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:28:52.058522Z",
     "start_time": "2019-09-02T15:28:51.917981Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df = customer_event_df.fillna('None', subset=['artist', 'song'])\n",
    "customer_event_df = customer_event_df.fillna(0, subset=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:30:17.354050Z",
     "start_time": "2019-09-02T15:28:53.502899Z"
    }
   },
   "outputs": [],
   "source": [
    "sumtable(customer_event_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "In this section, we perform EDA on `medium-sparkify-event-data.json` by exploring each of the features and extract useful insights from the data. First, we look at each feature individually and compute descriptive statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist\n",
    "\n",
    "* The most listened artist on Sparkify is Kings of Leon\n",
    "* Top 4 most listened artist are rock bands\n",
    "* Total of 21248 distinct artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:30:28.409440Z",
     "start_time": "2019-09-02T15:30:23.043392Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"artist\", \"userId\").groupby(\"artist\"). \\\n",
    "    agg({'artist': 'count'}).select('artist', 'count(artist)'). \\\n",
    "    sort(desc('count(artist)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:30:45.615768Z",
     "start_time": "2019-09-02T15:30:40.782021Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_count_artist = customer_event_df.select(\"artist\").distinct().count()\n",
    "print(f\"There are a total of {unique_count_artist} artists in this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T20:37:41.377244Z",
     "start_time": "2019-08-28T20:37:41.365481Z"
    }
   },
   "source": [
    "### auth\n",
    "\n",
    "* Two distinct values for authentication. Logged In and Cancelled.\n",
    "* only 99 instances have cancelled their authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:30:47.197180Z",
     "start_time": "2019-09-02T15:30:47.183631Z"
    }
   },
   "outputs": [],
   "source": [
    "def sns_barplot_text(x, y, data, title, hue=None, percentage=True, text=True,\n",
    "                     log=False, figsize=(8, 5)):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.barplot(x=x, y=y, data=data, hue=hue, ax=ax, log=log)\n",
    "    #ax.set_ylabel(f\"{data.columns[1]}\")\n",
    "    ax.set_xlabel(f\"{data.columns[0]}\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticklabels(data.iloc[:, 0].unique(), rotation=90)\n",
    "    if text:\n",
    "        for p in ax.patches:\n",
    "                height = p.get_height()\n",
    "                if percentage:\n",
    "                    ax.text(p.get_x() + p.get_width() / 2.,\n",
    "                            height,\n",
    "                            f'{height /data.loc[:,y].sum() * 100 :.2f}%',\n",
    "                            ha='center', fontsize=8)\n",
    "                else:\n",
    "                    ax.text(p.get_x() + p.get_width() / 2.,\n",
    "                            height,\n",
    "                            f'{height :.2f}',\n",
    "                            ha='center', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:30:53.050257Z",
     "start_time": "2019-09-02T15:30:47.958459Z"
    }
   },
   "outputs": [],
   "source": [
    "auth_count = customer_event_df.select(\"auth\", ).groupby(\"auth\"). \\\n",
    "    agg({'auth': 'count'}).select('auth', col('count(auth)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:30:54.357398Z",
     "start_time": "2019-09-02T15:30:54.131433Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text('auth', 'total', auth_count, title=\"Distribution of auth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### firstName and lastName\n",
    "\n",
    "* There are 345 distinct first name and 275 distinct last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:00.503854Z",
     "start_time": "2019-09-02T15:30:56.540585Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"firstName\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:06.014176Z",
     "start_time": "2019-09-02T15:31:02.297827Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"lastName\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### itemInSession\n",
    "\n",
    "* This is the number position of the event in the session\n",
    "* On averge, the number postition of the event is 107 in one single session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:10.762887Z",
     "start_time": "2019-09-02T15:31:08.116629Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"itemInSession\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:15.792369Z",
     "start_time": "2019-09-02T15:31:11.756853Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"itemInSession\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### length\n",
    "\n",
    "* Average song length is around 3 minutes and 20 seconds.\n",
    "* length 0 means that the user did not listen to any songs\n",
    "* longest song is around 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:21.094973Z",
     "start_time": "2019-09-02T15:31:18.437849Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"length\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method \n",
    "\n",
    "* GET is used to request data from a specified resource and PUT method is used to send data to a server to.\n",
    "* This means all the GET method are not listing to songs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:26.990644Z",
     "start_time": "2019-09-02T15:31:22.648409Z"
    }
   },
   "outputs": [],
   "source": [
    "method_count = customer_event_df.select(\"method\").groupby(\"method\"). \\\n",
    "    agg({'method': 'count'}).select('method', col('count(method)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:31.087097Z",
     "start_time": "2019-09-02T15:31:27.781422Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.filter(col(\"method\") == \"GET\").groupby('artist').agg({'artist': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:34.897136Z",
     "start_time": "2019-09-02T15:31:31.889346Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.filter(col(\"method\") == \"GET\").groupby('page').agg({'page': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:36.464053Z",
     "start_time": "2019-09-02T15:31:36.259378Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(\"method\", \"total\", method_count, title='Distribution of method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### registration and ts\n",
    "\n",
    "* both registration and ts are timestamp features in unix or ns format. We will clean it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:40.119099Z",
     "start_time": "2019-09-02T15:31:38.094862Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(['userId', 'registration', 'ts']).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### userId and sessionid\n",
    "\n",
    "* These are unqiues id and will be dropped during modelling\n",
    "* 448 unique userId and 4470 unique sessionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:46.406440Z",
     "start_time": "2019-09-02T15:31:42.232475Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(countDistinct('userId').alias('number_of_userId'), \n",
    "                         countDistinct('sessionId').alias('number_of_sessionId')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### song\n",
    "\n",
    "* The most listened songs are You're The One, Undo and Revelry.\n",
    "* For users that have None entry, they are on pages such as Thumbs up, Home and Add to Playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:56.983883Z",
     "start_time": "2019-09-02T15:31:47.999716Z"
    }
   },
   "outputs": [],
   "source": [
    "song_count = customer_event_df.select(\"song\", 'artist').groupby(\"song\"). \\\n",
    "    agg({'song': 'count'}).select('song', col('count(song)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:31:57.796534Z",
     "start_time": "2019-09-02T15:31:57.785680Z"
    }
   },
   "outputs": [],
   "source": [
    "song_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:02.340947Z",
     "start_time": "2019-09-02T15:31:58.835425Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.filter(col('song') == 'None').groupby('page'). \\\n",
    "    agg({'page': 'count'}).sort((desc('count(page)'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### status\n",
    "\n",
    "* 91.59% of the requested are succeeded with status code 200, 8.31% with status code 307 (redirect) and 0.1% of the requested page is 404 not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:07.883530Z",
     "start_time": "2019-09-02T15:32:04.165572Z"
    }
   },
   "outputs": [],
   "source": [
    "status_count = customer_event_df.select(\"status\", 'artist').groupby(\"status\"). \\\n",
    "    agg({'status': 'count'}).select('status', col('count(status)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:08.665112Z",
     "start_time": "2019-09-02T15:32:08.659830Z"
    }
   },
   "outputs": [],
   "source": [
    "status_count['status'] = status_count['status'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:09.996086Z",
     "start_time": "2019-09-02T15:32:09.795184Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text('status', 'total', status_count, title=\"Distribution of status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### userAgent\n",
    "\n",
    "* Majority of users using Sparkify app on desktop os\n",
    "* We extract the device OS, browser OS and browser version from the userAgent information to better capture the relationship of churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:15.505976Z",
     "start_time": "2019-09-02T15:32:12.079872Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"userAgent\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:20.935554Z",
     "start_time": "2019-09-02T15:32:16.648180Z"
    }
   },
   "outputs": [],
   "source": [
    "useragent_count = customer_event_df.select(\"userAgent\").groupby(\"userAgent\"). \\\n",
    "    agg({'userAgent': 'count'}).select('userAgent', col('count(userAgent)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:21.238694Z",
     "start_time": "2019-09-02T15:32:21.233692Z"
    }
   },
   "outputs": [],
   "source": [
    "# useragent_count['percentage'] = useragent_count['total'] / useragent_count['total'].sum() * 100\n",
    "# useragent_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:21.906809Z",
     "start_time": "2019-09-02T15:32:21.898562Z"
    }
   },
   "outputs": [],
   "source": [
    "def os_feature(s):\n",
    "    os = re.findall(\"Ubuntu|Windows|Mac|iPad|iPhone|Linux\", s)\n",
    "    if os:\n",
    "        os = os[0].translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "    \n",
    "    return os\n",
    "\n",
    "def browser_feature(s):\n",
    "    browser_list = re.findall(\"Chrome[/\\w+.]+|Safari[/\\w.]+|Mobile[/\\w.]+|Firefox[/\\w.]+|Trident[/\\w.]+\", s)\n",
    "    if browser_list:\n",
    "        browser = browser_list[0].strip().split(\"/\")[0]\n",
    "    \n",
    "    return browser\n",
    "\n",
    "def browser_version_feature(s):\n",
    "    browser_list = re.findall(\"Chrome[/\\w+.]+|Safari[/\\w.]+|Mobile[/\\w.]+|Firefox[/\\w.]+|Trident[/\\w.]+\", s)\n",
    "    if browser_list:\n",
    "        version = browser_list[0].strip().split(\"/\")[1]\n",
    "    \n",
    "    return version\n",
    "\n",
    "os_udf = udf(os_feature, StringType())\n",
    "browser_udf = udf(browser_feature, StringType())\n",
    "version_udf = udf(browser_version_feature, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:23.167583Z",
     "start_time": "2019-09-02T15:32:23.046686Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df = customer_event_df.withColumn(\"os\",\n",
    "                                                 os_udf(customer_event_df.userAgent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:24.567545Z",
     "start_time": "2019-09-02T15:32:24.520205Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df = customer_event_df.withColumn(\"browser\",\n",
    "                                                 browser_udf(customer_event_df.userAgent))\n",
    "customer_event_df = customer_event_df.withColumn(\"browser_ver\",\n",
    "                                                 version_udf(customer_event_df.userAgent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:31.525698Z",
     "start_time": "2019-09-02T15:32:25.786332Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"browser\").groupby(\"browser\"). \\\n",
    "    agg({'browser': 'count'}).select('browser', col('count(browser)').alias('total')). \\\n",
    "    sort(desc('total')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:37.948945Z",
     "start_time": "2019-09-02T15:32:33.916470Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"browser_ver\").groupby(\"browser_ver\"). \\\n",
    "    agg({'browser_ver': 'count'}).select('browser_ver', col('count(browser_ver)').alias('total')). \\\n",
    "    sort(desc('total')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Churn\n",
    "\n",
    "* There are 99 cancellation of subscription in this tiny dataset.\n",
    "* We create a `churn` label column for the dataset. It returns 1 if `Cancecllation Confirmation` events happens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:46.693701Z",
     "start_time": "2019-09-02T15:32:42.782721Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.filter(col(\"page\") == \"Cancellation Confirmation\" ). \\\n",
    "    select(\"userId\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:32:57.714674Z",
     "start_time": "2019-09-02T15:32:57.542786Z"
    }
   },
   "outputs": [],
   "source": [
    "is_cancellation = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n",
    "\n",
    "customer_event_df = customer_event_df.withColumn(\"churn\", is_cancellation(\"page\"))\n",
    "# there are users that cancelled their subscription in one of the session \n",
    "# we have to assign 1 to these users\n",
    "window_func = Window.partitionBy(\"userId\").rangeBetween(Window.unboundedPreceding,\n",
    "                                                        Window.unboundedFollowing)\n",
    "customer_event_df = customer_event_df.withColumn(\"churn\", Fsum(\"churn\").over(window_func))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis \n",
    "\n",
    "* In this section, we analyze how different features interact with the churn rate.\n",
    "* We convert the `ts` and `registration` feature into datetime object.\n",
    "* Extract day and week feature from `ts` to observe the churn rate of weekday and hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:01.121858Z",
     "start_time": "2019-09-02T15:32:58.864667Z"
    }
   },
   "outputs": [],
   "source": [
    "# ts feature\n",
    "customer_event_df.select(\"ts\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:01.997984Z",
     "start_time": "2019-09-02T15:33:01.992309Z"
    }
   },
   "outputs": [],
   "source": [
    "start_ts = int(1538352011000) / 1000\n",
    "start_date = datetime.utcfromtimestamp(start_ts).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Start Time: {start_date}\")\n",
    "\n",
    "end_ts = int(1543622466000) / 1000\n",
    "end_date = datetime.utcfromtimestamp(end_ts).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"End Time: {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:02.983064Z",
     "start_time": "2019-09-02T15:33:02.976233Z"
    }
   },
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(int(1543622466000) / 1000).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:05.733496Z",
     "start_time": "2019-09-02T15:33:05.676189Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_to_day_fn = udf(lambda ts: int(datetime.fromtimestamp(ts / 1000.0).strftime(\"%w\")), IntegerType())\n",
    "ts_to_hour_fn = udf(lambda ts: datetime.fromtimestamp(ts / 1000.0).hour, IntegerType())\n",
    "ts_to_date_fn = udf(lambda ts: datetime.fromtimestamp(ts / 1000.0).date(), DateType())\n",
    "ts_to_month_fn = udf(lambda ts: datetime.fromtimestamp(ts / 1000.0).month, IntegerType())\n",
    "\n",
    "customer_event_df = customer_event_df.withColumn(\"event_weekday\", \n",
    "                                                 ts_to_day_fn(customer_event_df.ts))\n",
    "customer_event_df = customer_event_df.withColumn(\"event_hour\", \n",
    "                                                 ts_to_hour_fn(customer_event_df.ts))\n",
    "customer_event_df = customer_event_df.withColumn(\"event_month\",\n",
    "                                                 ts_to_month_fn(customer_event_df.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:06.677616Z",
     "start_time": "2019-09-02T15:33:06.643698Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df = customer_event_df.withColumn(\"event_date\",\n",
    "                                                 ts_to_date_fn(customer_event_df.ts))\n",
    "customer_event_df = customer_event_df.withColumn(\"registration_date\",\n",
    "                                                 ts_to_date_fn(customer_event_df.registration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:07.492480Z",
     "start_time": "2019-09-02T15:33:07.469454Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_location(s):\n",
    "    \n",
    "    location = s.split(\",\")[1].strip()\n",
    "    \n",
    "    if len(location) >= 3:\n",
    "        location = location.split(\"-\")[0].strip()\n",
    "    return location\n",
    "\n",
    "clean_location_udf = udf(clean_location, StringType())\n",
    "\n",
    "customer_event_df = customer_event_df.withColumn(\"location\",\n",
    "                                                 clean_location_udf(customer_event_df.location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:08.599944Z",
     "start_time": "2019-09-02T15:33:08.595444Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:10.023705Z",
     "start_time": "2019-09-02T15:33:09.664056Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a temp view from customer_even_df to use SQL type of syntax for data analysis\n",
    "customer_event_df.createOrReplaceTempView('event');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:19.814364Z",
     "start_time": "2019-09-02T15:33:11.224412Z"
    }
   },
   "outputs": [],
   "source": [
    "churn_count_df = spark.sql(\"\"\"\n",
    "                           SELECT churn, \n",
    "                                  Count(DISTINCT userid) AS total_user \n",
    "                           FROM   event \n",
    "                           GROUP  BY churn \n",
    "                           \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:21.011164Z",
     "start_time": "2019-09-02T15:33:20.823108Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='churn', y='total_user', data=churn_count_df, title=\"Distrubtion of churn\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender and churn rate\n",
    "\n",
    "* Males user have a slighly more churn rate than female users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:27.967186Z",
     "start_time": "2019-09-02T15:33:24.074783Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_count = customer_event_df.select(\"gender\").groupby(\"gender\"). \\\n",
    "    agg({'gender': 'count'}).select('gender', col('count(gender)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:29.848069Z",
     "start_time": "2019-09-02T15:33:29.641789Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text('gender', 'total', gender_count, title=\"Distribution of gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:39.853726Z",
     "start_time": "2019-09-02T15:33:30.600179Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_churn_df = spark.sql(\"\"\"\n",
    "                           SELECT gender, \n",
    "                                  churn, \n",
    "                           Count(DISTINCT userid) AS total_user \n",
    "                           FROM   event \n",
    "                           GROUP  BY gender, \n",
    "                                     churn  \n",
    "                           \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:41.114281Z",
     "start_time": "2019-09-02T15:33:40.879614Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text('churn', 'total_user', gender_churn_df, hue='gender', \n",
    "                 title='Distrubtion of gender vs churn', percentage=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T20:10:06.916605Z",
     "start_time": "2019-08-30T20:10:06.905485Z"
    }
   },
   "source": [
    "### Subscription level and churn rate\n",
    "\n",
    "* The is the feature that distinguish free user and paid user.\n",
    "* Around 79.2% of the users are paid user, 20.8% are free users.\n",
    "* 82 users subscribe for one month and cancel their subscription. This may be \"first month trial\" offer by Sparkify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:47.272743Z",
     "start_time": "2019-09-02T15:33:43.072661Z"
    }
   },
   "outputs": [],
   "source": [
    "level_count = customer_event_df.select(\"level\").groupby(\"level\"). \\\n",
    "    agg({'level': 'count'}).select('level', col('count(level)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()\n",
    "\n",
    "sns_barplot_text('level', 'total', level_count, title=\"Distribution of level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:33:58.609205Z",
     "start_time": "2019-09-02T15:33:48.255666Z"
    }
   },
   "outputs": [],
   "source": [
    "level_churn_df = spark.sql(\"\"\"\n",
    "                           SELECT level, \n",
    "                                  churn, \n",
    "                           Count(DISTINCT userid) AS total_user \n",
    "                           FROM   event \n",
    "                           GROUP  BY level, \n",
    "                                     churn  \n",
    "                           ORDER BY churn\n",
    "                           \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:34:07.220462Z",
     "start_time": "2019-09-02T15:34:06.966857Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text('churn', 'total_user', data=level_churn_df, hue='level', \n",
    "                 title='Distrubtion of subscription level vs churn', percentage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:34:18.288066Z",
     "start_time": "2019-09-02T15:34:07.889542Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_level_churn_df = spark.sql(\"\"\"\n",
    "                                  SELECT level, \n",
    "                                         gender,\n",
    "                                         churn, \n",
    "                                  Count(DISTINCT userid) AS total_user \n",
    "                                  FROM   event \n",
    "                                  GROUP  BY level,\n",
    "                                            gender,\n",
    "                                            churn  \n",
    "                                  ORDER BY churn\n",
    "                                  \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:34:21.180590Z",
     "start_time": "2019-09-02T15:34:20.476565Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(gender_level_churn_df, col=\"level\",  row=\"gender\")\n",
    "g = g.map(sns.barplot, \"churn\", \"total_user\", edgecolor=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location and churn rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most of the users are from New Youk, LA, Boston and Chicago.\n",
    "* Once we define churn rate, it would  be interesting see the intersection of both features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:34:27.657534Z",
     "start_time": "2019-09-02T15:34:23.334379Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.select(\"location\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:04.754275Z",
     "start_time": "2019-09-02T15:35:00.005052Z"
    }
   },
   "outputs": [],
   "source": [
    "location_count = customer_event_df.select(\"location\").groupby(\"location\"). \\\n",
    "    agg({'location': 'count'}).select('location', col('count(location)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()\n",
    "\n",
    "location_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:15.470133Z",
     "start_time": "2019-09-02T15:35:07.262330Z"
    }
   },
   "outputs": [],
   "source": [
    "location_df = spark.sql(\"\"\"\n",
    "                           SELECT location, \n",
    "                                  Count(DISTINCT userid) AS total_user \n",
    "                           FROM   event \n",
    "                           GROUP  BY location \n",
    "                           ORDER BY total_user\n",
    "                           DESC\n",
    "                           \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:27.353120Z",
     "start_time": "2019-09-02T15:35:17.782089Z"
    }
   },
   "outputs": [],
   "source": [
    "location_churn_df = spark.sql(\"\"\"\n",
    "                           SELECT location, \n",
    "                                  Count(DISTINCT userid) AS churn_user \n",
    "                           FROM   event \n",
    "                           WHERE churn=1\n",
    "                           GROUP BY location\n",
    "                           \"\"\").toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:29.709509Z",
     "start_time": "2019-09-02T15:35:29.699944Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_df = location_churn_df.merge(location_df, on='location').sort_values(by='total_user', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:30.869627Z",
     "start_time": "2019-09-02T15:35:30.858724Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_df['percentage'] = merge_df['churn_user'] / merge_df['total_user'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:32.233747Z",
     "start_time": "2019-09-02T15:35:32.218372Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_df.sort_values(by='percentage', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:43.991212Z",
     "start_time": "2019-09-02T15:35:43.319085Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 15))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x='total_user', y='location', data=merge_df, ax=ax,\n",
    "            label='total_user',color='b')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='churn_user', y='location', data=merge_df, ax=ax, \n",
    "            label='churn_user',color='b')\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T21:48:52.870582Z",
     "start_time": "2019-08-31T21:48:45.278225Z"
    }
   },
   "source": [
    "### page insterection \n",
    "\n",
    "\n",
    "* Most frequent page is NextSong follows by Thumbs Up\n",
    "* NextSong account for almost 82% of the pages\n",
    "* Clearly pages is heavily linked to the churn rate of the user. We will dive deep into \n",
    "\n",
    "#### page with level\n",
    "\n",
    "* More users submit upgrade then users submit downgrades\n",
    "* As expected, more free users rolls advert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:51.072970Z",
     "start_time": "2019-09-02T15:35:46.687127Z"
    }
   },
   "outputs": [],
   "source": [
    "page_count = customer_event_df.select(\"page\").groupby(\"page\"). \\\n",
    "    agg({'page': 'count'}).select('page', col('count(page)').alias('total')). \\\n",
    "    sort(desc('total')).toPandas()\n",
    "\n",
    "page_count['percentage'] = page_count['total']/ page_count['total'].sum()\n",
    "\n",
    "page_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:53.175294Z",
     "start_time": "2019-09-02T15:35:52.256429Z"
    }
   },
   "outputs": [],
   "source": [
    "current_palette = sns.color_palette()\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "sns.barplot(x=page_count['total'],\n",
    "            y=page_count['page'],\n",
    "            log=True,\n",
    "            ax=ax,\n",
    "            palette=current_palette)\n",
    "ax.set_title(\"Page Distribution\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:35:58.000735Z",
     "start_time": "2019-09-02T15:35:54.503545Z"
    }
   },
   "outputs": [],
   "source": [
    "page_gender_df = spark.sql(\"\"\"\n",
    "                    SELECT page,\n",
    "                           gender,\n",
    "                           COUNT(userId) AS total_visit\n",
    "                    FROM   event\n",
    "                    GROUP BY page,\n",
    "                             gender\n",
    "                    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:36:00.207776Z",
     "start_time": "2019-09-02T15:35:59.450930Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='page', y='total_visit', data=page_gender_df, hue=\"gender\",\n",
    "                 title=\"Distribution of page and gender\", percentage=False,\n",
    "                 text=False, log=True, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:36:11.965995Z",
     "start_time": "2019-09-02T15:36:01.654812Z"
    }
   },
   "outputs": [],
   "source": [
    "page_churn_df = spark.sql(\"\"\"\n",
    "                    SELECT page,\n",
    "                           churn,\n",
    "                           COUNT(DISTINCT(userId)) AS total_user\n",
    "                    FROM   event\n",
    "                    GROUP BY page,\n",
    "                             churn\n",
    "                    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:36:15.273299Z",
     "start_time": "2019-09-02T15:36:14.781088Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='page', y='total_user', data=page_churn_df, hue=\"churn\",\n",
    "                 title=\"Distribution of page and churn\", percentage=False,\n",
    "                 text=False, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day, hour feature intersection\n",
    "\n",
    "#### Day of the week page visit churn rate\n",
    "\n",
    "* less users using Sparkify on Sunday and Saturday resulting less churn\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:39:04.302975Z",
     "start_time": "2019-09-02T15:36:21.191998Z"
    }
   },
   "outputs": [],
   "source": [
    "day_user_churn_df = spark.sql(\"\"\"\n",
    "                    SELECT event_weekday,\n",
    "                           churn,\n",
    "                           COUNT(DISTINCT(userId)) AS total_user\n",
    "                    FROM   event\n",
    "                    GROUP BY event_weekday,\n",
    "                             churn\n",
    "                    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:39:11.858612Z",
     "start_time": "2019-09-02T15:39:11.851255Z"
    }
   },
   "outputs": [],
   "source": [
    "day_user_churn_df = day_user_churn_df.sort_values(by=\"event_weekday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:39:13.615975Z",
     "start_time": "2019-09-02T15:39:13.287202Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='event_weekday', y='total_user', data=day_user_churn_df, hue=\"churn\",\n",
    "                 title=\"Distribution of user by day with churn status\", percentage=False,\n",
    "                 text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:41:56.984258Z",
     "start_time": "2019-09-02T15:39:15.572138Z"
    }
   },
   "outputs": [],
   "source": [
    "day_event_churn_df = spark.sql(\"\"\"\n",
    "                    SELECT event_weekday,\n",
    "                           churn,\n",
    "                           COUNT(userId) AS total_event\n",
    "                    FROM   event\n",
    "                    GROUP BY event_weekday,\n",
    "                             churn\n",
    "                    ORDER BY event_weekday\n",
    "                    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:42:15.674708Z",
     "start_time": "2019-09-02T15:42:15.303198Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='event_weekday', y='total_event', data=day_event_churn_df, hue=\"churn\",\n",
    "                 title=\"Distribution of user event with churn status\", percentage=False,\n",
    "                 text=True, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:44:41.031355Z",
     "start_time": "2019-09-02T15:42:21.881201Z"
    }
   },
   "outputs": [],
   "source": [
    "hour_user_churn_df = spark.sql(\"\"\"\n",
    "                    SELECT event_hour,\n",
    "                           churn,\n",
    "                           COUNT(DISTINCT(userId)) AS total_user\n",
    "                    FROM   event\n",
    "                    GROUP BY event_hour,\n",
    "                             churn\n",
    "                    ORDER BY event_hour\n",
    "                    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:46:02.132365Z",
     "start_time": "2019-09-02T15:46:01.461897Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='event_hour', y='total_user', data=hour_user_churn_df, hue=\"churn\",\n",
    "                 title=\"Distribution of user by hour with churn status\", percentage=False,\n",
    "                 text=False, figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:47:57.433997Z",
     "start_time": "2019-09-02T15:46:05.655872Z"
    }
   },
   "outputs": [],
   "source": [
    "hour_event_churn_df = spark.sql(\"\"\"\n",
    "                    SELECT event_hour,\n",
    "                           churn,\n",
    "                           COUNT(userId) AS total_event\n",
    "                    FROM   event\n",
    "                    GROUP BY event_hour,\n",
    "                             churn\n",
    "                    ORDER BY event_hour\n",
    "                    \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:48:00.223483Z",
     "start_time": "2019-09-02T15:47:59.689372Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='event_hour', y='total_event', data=hour_event_churn_df, hue=\"churn\",\n",
    "                 title=\"Distribution of user event with churn status\", percentage=False,\n",
    "                 text=False, figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:49:56.341413Z",
     "start_time": "2019-09-02T15:48:01.131480Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_counts_df = spark.sql(\"\"\"\n",
    "                            SELECT event_date,\n",
    "                                   churn,\n",
    "                                   COUNT(userId) AS total_event\n",
    "                            FROM   event\n",
    "                            GROUP BY event_date,\n",
    "                                     churn\n",
    "                            ORDER BY event_date\n",
    "                            \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:50:01.075039Z",
     "start_time": "2019-09-02T15:50:00.644723Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(x=\"event_date\",\n",
    "             y='total_event',\n",
    "             hue='churn',\n",
    "             data=daily_counts_df,\n",
    "             ax=ax)\n",
    "plt.xticks(rotation=30, ha=\"right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:04.364389Z",
     "start_time": "2019-09-02T15:50:06.822922Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_user_counts_df = spark.sql(\"\"\"\n",
    "                                 SELECT event_date,\n",
    "                                        churn,\n",
    "                                        COUNT(DISTINCT(userId)) AS total_user\n",
    "                                 FROM   event\n",
    "                                 GROUP BY event_date,\n",
    "                                          churn\n",
    "                                 ORDER BY event_date\n",
    "                                \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:08.914783Z",
     "start_time": "2019-09-02T15:52:08.590887Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(x=\"event_date\",\n",
    "             y='total_user',\n",
    "             hue='churn',\n",
    "             data=daily_user_counts_df,\n",
    "             ax=ax)\n",
    "ax.set_title(\"Daily user count according to churn status \")\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"count\")\n",
    "plt.xticks(rotation=30, ha=\"right\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:13.125431Z",
     "start_time": "2019-09-02T15:52:13.118440Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_event_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### useragent related features\n",
    "\n",
    "#### browser\n",
    "\n",
    "* 40% of mobile browser users has churn. 26% of Firefox user churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:28.992156Z",
     "start_time": "2019-09-02T15:52:18.135006Z"
    }
   },
   "outputs": [],
   "source": [
    "browser_churn_df = spark.sql(\"\"\"\n",
    "                            SELECT browser,\n",
    "                                   churn,\n",
    "                                   COUNT(DISTINCT(userId)) AS total_user\n",
    "                            FROM   event\n",
    "                            GROUP BY browser,\n",
    "                                     churn\n",
    "                            ORDER BY browser\n",
    "                            \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:32.443700Z",
     "start_time": "2019-09-02T15:52:32.432479Z"
    }
   },
   "outputs": [],
   "source": [
    "browser_churn_df.groupby(\"browser\")['total_user'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:42.788368Z",
     "start_time": "2019-09-02T15:52:42.776710Z"
    }
   },
   "outputs": [],
   "source": [
    "browser_churn_df.loc[browser_churn_df.churn==1, 'total_user'] / browser_churn_df.groupby(\"browser\")['total_user'].sum().values * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:52:49.205294Z",
     "start_time": "2019-09-02T15:52:48.921224Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='browser', y='total_user', data=browser_churn_df, hue='churn',\n",
    "                 title=\"Distribution of user browser with churn\", percentage=False,\n",
    "                 text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### os\n",
    "\n",
    "* 61% of iphone os users has churned, no ipad users churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:53:05.207729Z",
     "start_time": "2019-09-02T15:52:53.395544Z"
    }
   },
   "outputs": [],
   "source": [
    "os_churn_df = spark.sql(\"\"\"\n",
    "                        SELECT os,\n",
    "                               churn,\n",
    "                               COUNT(DISTINCT(userId)) AS total_user\n",
    "                        FROM   event\n",
    "                        GROUP BY os,\n",
    "                                 churn\n",
    "                        ORDER BY os\n",
    "                        \"\"\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:53:06.864098Z",
     "start_time": "2019-09-02T15:53:06.408682Z"
    }
   },
   "outputs": [],
   "source": [
    "sns_barplot_text(x='os', y='total_user', data=os_churn_df, hue='churn',\n",
    "                 title=\"Distribution of user os with churn\", percentage=False,\n",
    "                 text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:53:18.631241Z",
     "start_time": "2019-09-02T15:53:09.475663Z"
    }
   },
   "outputs": [],
   "source": [
    "os_level_df = spark.sql(\"\"\"\n",
    "                        SELECT os,\n",
    "                               level,\n",
    "                               COUNT(DISTINCT(userId)) AS total_user\n",
    "                        FROM   event\n",
    "                        GROUP BY os,\n",
    "                                 level\n",
    "                        ORDER BY os\n",
    "                        \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total number of artist listened\n",
    "\n",
    "* count the number of aritst each userid listened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:53:46.967676Z",
     "start_time": "2019-09-02T15:53:23.926161Z"
    }
   },
   "outputs": [],
   "source": [
    "count_artist = customer_event_df \\\n",
    "    .filter(col(\"page\") == \"NextSong\") \\\n",
    "    .select(\"userId\", \"artist\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'total_artist') \\\n",
    "\n",
    "count_artist.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarise gender, level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:53:52.809775Z",
     "start_time": "2019-09-02T15:53:49.771296Z"
    }
   },
   "outputs": [],
   "source": [
    "binarize_gender = customer_event_df \\\n",
    "    .select(\"userId\", \"gender\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .replace([\"M\", \"F\"], [\"0\", \"1\"], \"gender\") \\\n",
    "    .select(\"userId\", col(\"gender\").cast(\"int\"))\n",
    "\n",
    "binarize_gender.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:53:59.456504Z",
     "start_time": "2019-09-02T15:53:56.411166Z"
    }
   },
   "outputs": [],
   "source": [
    "binarize_level = customer_event_df \\\n",
    "    .select(\"userId\", \"level\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .replace([\"free\", \"paid\"], [\"0\", \"1\"], 'level') \\\n",
    "    .select(\"userId\", col(\"level\").cast(\"int\"))\n",
    "\n",
    "binarize_level.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page features\n",
    "\n",
    "### downgrades page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:04.984299Z",
     "start_time": "2019-09-02T15:54:02.302015Z"
    }
   },
   "outputs": [],
   "source": [
    "downgrade_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"page\") \\\n",
    "    .where(col(\"page\") == \"Downgrade\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_downgrade\")\n",
    "\n",
    "downgrade_feat.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll Advert page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:09.549080Z",
     "start_time": "2019-09-02T15:54:06.977039Z"
    }
   },
   "outputs": [],
   "source": [
    "advert_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"page\") \\\n",
    "    .where(col(\"page\") == \"Roll Advert\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_advert\")\n",
    "\n",
    "advert_feat.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add to playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:13.954615Z",
     "start_time": "2019-09-02T15:54:11.345826Z"
    }
   },
   "outputs": [],
   "source": [
    "playlist_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"page\") \\\n",
    "    .where(col(\"page\") == \"Add to Playlist\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_song_playlist\")\n",
    "\n",
    "playlist_feat.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thumbs down and thumbs up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:18.598076Z",
     "start_time": "2019-09-02T15:54:16.159631Z"
    }
   },
   "outputs": [],
   "source": [
    "thumbs_down_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"page\") \\\n",
    "    .where(col(\"page\") == \"Thumbs Down\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_thumbs_down\")\n",
    "\n",
    "thumbs_down_feat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:22.299702Z",
     "start_time": "2019-09-02T15:54:19.808220Z"
    }
   },
   "outputs": [],
   "source": [
    "thumbs_up_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"page\") \\\n",
    "    .where(col(\"page\") == \"Thumbs Up\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_thumbs_up\")\n",
    "\n",
    "thumbs_down_feat.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:26.657574Z",
     "start_time": "2019-09-02T15:54:24.155961Z"
    }
   },
   "outputs": [],
   "source": [
    "friend_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"page\") \\\n",
    "    .where(col(\"page\") == \"Add Friend\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_friend\")\n",
    "\n",
    "friend_feat.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total length of time listened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:31.542497Z",
     "start_time": "2019-09-02T15:54:28.688981Z"
    }
   },
   "outputs": [],
   "source": [
    "total_length = customer_event_df \\\n",
    "    .select(\"userId\", \"length\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .sum() \\\n",
    "    .withColumnRenamed(\"sum(length)\", 'total_length')\n",
    "    \n",
    "total_length.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of songs listened \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:36.138509Z",
     "start_time": "2019-09-02T15:54:33.601123Z"
    }
   },
   "outputs": [],
   "source": [
    "total_songs = customer_event_df \\\n",
    "    .select(\"userId\", \"song\") \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"num_song\") \n",
    "\n",
    "total_songs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of sessions per user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:54:46.116393Z",
     "start_time": "2019-09-02T15:54:37.897805Z"
    }
   },
   "outputs": [],
   "source": [
    "num_session = customer_event_df \\\n",
    "    .select(\"userId\", \"sessionId\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed('count', 'session') \n",
    "\n",
    "num_session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average songs per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:55:01.830193Z",
     "start_time": "2019-09-02T15:54:53.331114Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_songs_session = customer_event_df.filter(col(\"page\") == \"NextSong\") \\\n",
    "    .groupby(\"userId\", \"sessionId\") \\\n",
    "    .count() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .agg({\"count\": \"avg\"}) \\\n",
    "    .withColumnRenamed(\"avg(count)\", \"avg_songs\") \n",
    "    \n",
    "\n",
    "avg_songs_session.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average session per day/month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:55:04.527851Z",
     "start_time": "2019-09-02T15:55:04.461788Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_sess = customer_event_df.groupby(['userId', 'event_weekday']).agg(countDistinct('sessionId')) \\\n",
    "    .groupby('userId').avg('count(DISTINCT sessionId)') \\\n",
    "    .withColumnRenamed('avg(count(DISTINCT sessionId))', 'avg_daily_sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:56:58.206732Z",
     "start_time": "2019-09-02T15:55:08.978093Z"
    }
   },
   "outputs": [],
   "source": [
    "month_sess = customer_event_df.groupby(['userId', 'event_month']).agg(countDistinct('sessionId')) \\\n",
    "    .groupby('userId').avg('count(DISTINCT sessionId)') \\\n",
    "    .withColumnRenamed('avg(count(DISTINCT sessionId))', 'avg_monthly_sessions')\n",
    "month_sess.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## location feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:57:09.052441Z",
     "start_time": "2019-09-02T15:57:09.033242Z"
    }
   },
   "outputs": [],
   "source": [
    "location_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"location\") \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T22:22:52.455912Z",
     "start_time": "2019-09-01T22:22:47.830558Z"
    }
   },
   "source": [
    "##  os and browser features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:57:10.193185Z",
     "start_time": "2019-09-02T15:57:10.180686Z"
    }
   },
   "outputs": [],
   "source": [
    "os_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"os\") \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:57:10.991229Z",
     "start_time": "2019-09-02T15:57:10.973790Z"
    }
   },
   "outputs": [],
   "source": [
    "browser_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"browser\") \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:57:12.123243Z",
     "start_time": "2019-09-02T15:57:12.102857Z"
    }
   },
   "outputs": [],
   "source": [
    "browser_ver_feat = customer_event_df \\\n",
    "    .select(\"userId\", \"browser_ver\") \\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:57:23.923562Z",
     "start_time": "2019-09-02T15:57:12.762564Z"
    }
   },
   "outputs": [],
   "source": [
    "label = customer_event_df \\\n",
    "    .select('userId', col('churn').alias('label')) \\\n",
    "    .dropDuplicates() \\\n",
    "    .orderBy(\"userId\")\n",
    "\n",
    "label.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T15:58:05.115805Z",
     "start_time": "2019-09-02T15:58:04.532945Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed_event = count_artist.join(binarize_gender, \"userId\", \"outer\") \\\n",
    "    .join(binarize_level, \"userId\", \"outer\") \\\n",
    "    .join(downgrade_feat, \"userId\", \"outer\") \\\n",
    "    .join(advert_feat, \"userId\", \"outer\") \\\n",
    "    .join(playlist_feat, \"userId\", \"outer\") \\\n",
    "    .join(thumbs_down_feat, \"userId\", \"outer\") \\\n",
    "    .join(thumbs_up_feat, \"userId\", \"outer\") \\\n",
    "    .join(friend_feat, \"userId\", \"outer\") \\\n",
    "    .join(total_length, \"userId\", \"outer\") \\\n",
    "    .join(total_songs, \"userId\", \"outer\") \\\n",
    "    .join(num_session, \"userId\", \"outer\") \\\n",
    "    .join(avg_songs_session, \"userId\", \"outer\") \\\n",
    "    .join(daily_sess, \"userId\", \"outer\") \\\n",
    "    .join(month_sess, \"userId\", \"outer\") \\\n",
    "    .join(location_feat, \"userId\", \"outer\") \\\n",
    "    .join(os_feat, \"userId\", \"outer\") \\\n",
    "    .join(browser_feat, \"userId\", \"outer\") \\\n",
    "    .join(browser_ver_feat, \"userId\", \"outer\") \\\n",
    "    .join(label, \"userId\", \"outer\") \\\n",
    "    .drop(\"userId\") \\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T16:05:21.607846Z",
     "start_time": "2019-09-02T15:58:06.347067Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T16:13:56.273443Z",
     "start_time": "2019-09-02T16:13:56.235763Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_pd = transformed_event.toPandas()\n",
    "# dataset_pd.to_csv(\"../data/preprocessed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:34:35.907979Z",
     "start_time": "2019-09-02T18:34:35.747647Z"
    }
   },
   "outputs": [],
   "source": [
    "# customer_df = spark.read.csv(\"../data/preprocessed_dataset.csv\", header=True)\n",
    "# customer_df = customer_df.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T19:00:12.959Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:40:06.592015Z",
     "start_time": "2019-09-02T18:40:06.584076Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:34:37.142827Z",
     "start_time": "2019-09-02T18:34:37.121655Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = [\"location\", \"os\", \"browser\", \"browser_ver\"]\n",
    "num_cols= [\"total_artist\", \"gender\", \"level\", \"num_downgrade\", \"num_advert\", \"num_song_playlist\",\n",
    "           \"num_thumbs_down\", \"num_thumbs_up\", \"num_friend\", \"total_length\", \"num_song\",\n",
    "           \"session\", \"avg_songs\", \"avg_daily_sessions\", \"avg_monthly_sessions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:34:37.974910Z",
     "start_time": "2019-09-02T18:34:37.940462Z"
    }
   },
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_index\") for c in cat_cols]\n",
    "\n",
    "encoders = [StringIndexer(inputCol=indexer.getOutputCol(), \n",
    "                          outputCol=f\"{indexer.getOutputCol()}_encoded\")\n",
    "            for indexer in indexers]\n",
    "assemblerCat = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders],\n",
    "                               outputCol=\"cat\")\n",
    "pipelineCat = Pipeline(stages=indexers+encoders+[assemblerCat])\n",
    "customer_df = pipelineCat.fit(customer_df).transform(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:38:02.955291Z",
     "start_time": "2019-09-02T18:38:02.910837Z"
    }
   },
   "outputs": [],
   "source": [
    "assemblerNum = VectorAssembler(inputCols=num_cols, outputCol=\"num\")\n",
    "pipelineNum = Pipeline(stages=[assemblerNum])\n",
    "customer_df = pipelineNum.fit(customer_df).transform(customer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:34:32.039195Z",
     "start_time": "2019-09-02T18:34:32.034958Z"
    }
   },
   "outputs": [],
   "source": [
    "del indexers, encoders, assemblerCat, pipelineCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T18:34:32.393911Z",
     "start_time": "2019-09-02T18:34:32.387837Z"
    }
   },
   "outputs": [],
   "source": [
    "del customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
